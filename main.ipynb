{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "what we want to achieve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking if we can scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.robotparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def can_scrape(url: str, user_agent: str = \"*\") -> bool:\n",
    "    # create an instance of robot parser\n",
    "    rp = urllib.robotparser.RobotFileParser()\n",
    "\n",
    "    # parse the robots.txt file on the website\n",
    "    rp.set_url(url + \"/robots.txt\")\n",
    "    rp.read()\n",
    "\n",
    "    # check if scraping is allowed for the given user agent\n",
    "    return rp.can_fetch(user_agent, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "website_url = \"https://www.wikipedia.org\"\n",
    "user_agent = \"*\"\n",
    "\n",
    "can_scrape(website_url, user_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define custom function for getting html, calling it on the url and saving it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(url, path):\n",
    "    response = requests.get(url)\n",
    "    with open(path, \"w\", encoding = \"utf-8\") as f:\n",
    "        f.write(response.text)\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_old-growth_forests\"\n",
    "\n",
    "get_html(url, path=\"HTML/wiki_old_forrest.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create `BeautifulSoup` object and extract all `wikitable sortable` classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"HTML/wiki_old_forrest.html\", \"r\", encoding = \"utf-8\") as f:\n",
    "    html = f.read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "tables = soup.find_all(\"table\", attrs={\"class\": \"wikitable sortable\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the table names based on headers in the html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for table in tables:\n",
    "    headings = table.find_previous([\"h2\", \"h3\"]).text\n",
    "    print(headings)\n",
    "    data[headings] = table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the headers of tables using the Australia table as template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = data[\"Australia\"]\n",
    "first_row = table.tr\n",
    "\n",
    "columns = []\n",
    "for td in first_row:\n",
    "    if td.text.strip() != \"\":\n",
    "        columns.append(td.text.strip())\n",
    "\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a missing td in United States table (lol), so in order for everything to work we need to add it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_row_data(columns, row):\n",
    "    row_data = {}\n",
    "    table_cells = row.find_all(\"td\")\n",
    "    \n",
    "    # Add missing <td> cells if the number of columns is greater than table_cells\n",
    "    while len(table_cells) < len(columns):\n",
    "        empty_td = soup.new_tag(\"td\")   # Create a new empty <td> tag\n",
    "        \n",
    "        # Add a whitespace character that matches `\\s`, such as a space\n",
    "        #empty_td.string = \" \"           # Single space character\n",
    "        \n",
    "        row.append(empty_td)            # Append to the row\n",
    "        table_cells.append(empty_td)     # Add to the table_cells list\n",
    "\n",
    "    # Loop through the cells and map them to columns\n",
    "    for i in range(len(columns)):\n",
    "        row_data[columns[i]] = table_cells[i].text.strip()  # Extract text content\n",
    "\n",
    "    return row_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_row_data(row: dict):\n",
    "\n",
    "    for k in row.keys():\n",
    "        val = row[k]\n",
    "\n",
    "        if re.match(\"\\s\", val.text):\n",
    "            row[k] = \"No data\"\n",
    "\n",
    "        links = val.find_all(\"a\")\n",
    "\n",
    "        for l in links:\n",
    "            if l.get(\"title\") is not None and \"(page does not exist)\" in l.get(\"title\"):\n",
    "                l.replace_with(l.text)\n",
    "\n",
    "            if \"cite\" in l.get(\"href\"):\n",
    "                l.parent.decompose()\n",
    "\n",
    "        if k == \"Old-growth extent\" and row[k] != \"No data\":\n",
    "            data = row[k].text.strip()\n",
    "\n",
    "            data = data.replace(\"\\xa0\", \" \")\n",
    "            \n",
    "            # 2,000, 7,800,000\n",
    "            data = re.search(\"\\d+(?:,\\d{3})*(?:\\.\\d*)? (?:hectares|square kilometres|ha|acres)\", data).group()\n",
    "\n",
    "            parent = row[k].parent\n",
    "            row[k].decompose()\n",
    "\n",
    "            new_tag = soup.new_tag(\"td\")\n",
    "            new_tag.string = data\n",
    "            parent.append(new_tag)\n",
    "\n",
    "            row[k] = new_tag\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_table_data(columns, table):\n",
    "    table_data = []\n",
    "\n",
    "    rows = table.find_all(\"tr\")\n",
    "    rows.pop(0)\n",
    "\n",
    "    for r in rows:\n",
    "        r = extract_row_data(columns=columns, row=r)\n",
    "        r = clean_row_data(r)\n",
    "        table_data.append(r)\n",
    "\n",
    "    return table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_all_tables(columns, data):\n",
    "    for k in data.keys():\n",
    "        data[k] = prepare_table_data(columns, data[k])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = prepare_all_tables(columns, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = data[\"United States\"].find_all(\"tr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = data[\"United States\"].find_all(\"tr\")\n",
    "rows.pop(0)\n",
    "rows[167].find_all(\"td\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows[165].find_all(\"td\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_data = {}\n",
    "table_cells = rows[165].find_all(\"td\")\n",
    "for i in range(len(table_cells)):\n",
    "    row_data[columns[i]] = table_cells[i].text.strip() \n",
    "    \n",
    "row_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_data = {}\n",
    "table_cells = rows[167].find_all(\"td\")\n",
    "for i in range(len(table_cells)):\n",
    "    row_data[columns[i]] = table_cells[i].text.strip() \n",
    "    \n",
    "row_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = data[\"United States\"].find_all(\"tr\")\n",
    "rows.pop(0)\n",
    "\n",
    "table_data = []\n",
    "\n",
    "\n",
    "for row in rows:\n",
    "    r = extract_row_data(columns, row)\n",
    "    rr = clean_row_data(r)\n",
    "    table_data.append(rr)\n",
    "\n",
    "table_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data[\"Australia\"][3][\"Old-growth extent\"].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many of the listed forests are in France?\n",
    "europe = data[\"Europe\"]\n",
    "france = [r for r in europe if \"France\" in r[\"Country\"].text]\n",
    "len(france)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many of the listed forests are in Tasmania?\n",
    "len([r for r in data[\"Australia\"] if \"Tasmania\" in r[\"Area\"].text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In tasmania, of those that have data, what is the total area of these?\n",
    "australia = data[\"Australia\"]\n",
    "tasmania = [r for r in data[\"Australia\"] if \"Tasmania\" in r[\"Area\"].text]\n",
    "tasmania_area_data = [r for r in tasmania if r[\"Old-growth extent\"] != \"No data\"]\n",
    "\n",
    "total = 0\n",
    "for r in tasmania_area_data:\n",
    "    area = r[\"Old-growth extent\"].text\n",
    "\n",
    "    area = area.replace(\",\", \"\")\n",
    "    val = re.search(\"\\d*\", area).group()\n",
    "    val = float(val)\n",
    "\n",
    "    if \"square kilometres\" in area:\n",
    "        val = val * 100\n",
    "\n",
    "    total += val\n",
    "\n",
    "print(\"Total area for Tasmania forests: \", total, \" ha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From the data of bulgaria's forests, what is the proportion of bulgarias total area that is covered by these?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulgaria_rows = []\n",
    "for row in data[\"Europe\"]:\n",
    "    if row[\"Country\"].text.strip() == \"Bulgaria\":\n",
    "        bulgaria_rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the link of the bulgaria article\n",
    "bulgaria_link = \"https://wikipedia.org\" + bulgaria_rows[0][\"Country\"].a[\"href\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_html(bulgaria_link, path=\"HTML/bulgaria.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"HTML/bulgaria.html\", \"r\", encoding = \"utf-8\") as f:\n",
    "    html_bulgaria = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulgaria_soup = BeautifulSoup(html_bulgaria, \"html.parser\")\n",
    "bulgaria_soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bulgaria_area(tag):\n",
    "    return tag.name == \"td\" and 'km' in tag.text and 'Total' in tag.parent.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_tags = [t.text for t in bulgaria_soup.find_all(get_bulgaria_area)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_tag = km_tags[0]\n",
    "area_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_area = re.search(\"\\d+(?:,\\d{3})*(?:\\.\\d*)?\", area_tag).group()\n",
    "b_area = float(b_area.replace(',', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_area = b_area * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_total = 0\n",
    "for row in bulgaria_rows:\n",
    "    forest_data = row['Old-growth extent'].text\n",
    "    forest_data = re.search(\"\\d+(?:,\\d{3})*(?:\\.\\d*)?\", forest_data).group()\n",
    "    forest_data = float(forest_data.replace(',', ''))\n",
    "\n",
    "    forest_total += forest_data\n",
    "\n",
    "forest_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Percentage of bulgarian land area accounted for old growth: {round((forest_total / b_area)*100, 5)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many US states have forests with some variety of oak tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_table = data['United States']\n",
    "states = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_oak = [r for r in us_table if \"oak\" in r[\"Old-growth forest type\"].text]\n",
    "len(us_oak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in us_table:\n",
    "    f_type = r[\"Old-growth forest type\"]\n",
    "    if f_type is not None and f_type != 'No data':\n",
    "        if 'oak' in f_type.text.lower():\n",
    "            states.add(r[\"Country\"].text.strip())\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
