{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "what we want to achieve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking if we can scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.robotparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def can_scrape(url: str, user_agent: str = \"*\") -> bool:\n",
    "    # create an instance of robot parser\n",
    "    rp = urllib.robotparser.RobotFileParser()\n",
    "\n",
    "    # parse the robots.txt file on the website\n",
    "    rp.set_url(url + \"/robots.txt\")\n",
    "    rp.read()\n",
    "\n",
    "    # check if scraping is allowed for the given user agent\n",
    "    return rp.can_fetch(user_agent, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_url = \"https://www.wikipedia.org\"\n",
    "user_agent = \"*\"\n",
    "\n",
    "can_scrape(website_url, user_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define custom function for getting html, calling it on the url and saving it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(url, path):\n",
    "    response = requests.get(url)\n",
    "    with open(path, \"w\", encoding = \"utf-8\") as f:\n",
    "        f.write(response.text)\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_old-growth_forests\"\n",
    "\n",
    "get_html(url, path=\"HTML/wiki_old_forrest.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create `BeautifulSoup` object and extract all `wikitable sortable` classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"HTML/wiki_old_forrest.html\", \"r\", encoding = \"utf-8\") as f:\n",
    "    html = f.read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "tables = soup.find_all(\"table\", attrs={\"class\": \"wikitable sortable\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the table names based on headers in the html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Africa\n",
      "Asia\n",
      "Australia\n",
      "Europe\n",
      "Canada\n",
      "United States\n",
      "Central America\n",
      "Caribbean\n",
      "South America\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for table in tables:\n",
    "    headings = table.find_previous([\"h2\", \"h3\"]).text\n",
    "    print(headings)\n",
    "    data[headings] = table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the headers of tables using the Australia table as template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Country',\n",
       " 'Area',\n",
       " 'Old-growth extent',\n",
       " 'WWF ecoregion',\n",
       " 'Old-growth forest type']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = data[\"Australia\"]\n",
    "first_row = table.tr\n",
    "\n",
    "columns = []\n",
    "for td in first_row:\n",
    "    if td.text.strip() != \"\":\n",
    "        columns.append(td.text.strip())\n",
    "\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a missing td in United States table (lol), so in order for everything to work we need to REMOVE THE WHOLE DATASET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data[\"United States\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Africa', 'Asia', 'Australia', 'Europe', 'Canada', 'Central America', 'Caribbean', 'South America'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_row_data(columns, row):\n",
    "    row_data = {}\n",
    "    table_cells = row.find_all(\"td\")\n",
    "    \n",
    "    for i in range(len(table_cells)):\n",
    "        row_data[columns[i]] = table_cells[i]\n",
    "\n",
    "    return row_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_row_data(row: dict):\n",
    "\n",
    "    for k in row.keys():\n",
    "        val = row[k]\n",
    "\n",
    "        if re.match(\"\\s\", val.text):\n",
    "            row[k] = \"No data\"\n",
    "\n",
    "        links = val.find_all(\"a\")\n",
    "\n",
    "        for l in links:\n",
    "            if l.get(\"title\") is not None and \"(page does not exist)\" in l.get(\"title\"):\n",
    "                l.replace_with(l.text)\n",
    "\n",
    "            if \"cite\" in l.get(\"href\"):\n",
    "                l.parent.decompose()\n",
    "\n",
    "        if k == \"Old-growth extent\" and row[k] != \"No data\":\n",
    "            data = row[k].text.strip()\n",
    "\n",
    "            data = data.replace(\"\\xa0\", \" \")\n",
    "            \n",
    "            # 2,000, 7,800,000\n",
    "            data = re.search(\"\\d+(?:,\\d{3})*(?:\\.\\d*)? (?:hectares|square kilometres|ha|acres)\", data).group()\n",
    "\n",
    "            parent = row[k].parent\n",
    "            row[k].decompose()\n",
    "\n",
    "            new_tag = soup.new_tag(\"td\")\n",
    "            new_tag.string = data\n",
    "            parent.append(new_tag)\n",
    "\n",
    "            row[k] = new_tag\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_table_data(columns, table):\n",
    "    table_data = []\n",
    "\n",
    "    rows = table.find_all(\"tr\")\n",
    "    rows.pop(0)\n",
    "\n",
    "    for r in rows:\n",
    "        r = extract_row_data(columns=columns, row=r)\n",
    "        r = clean_row_data(r)\n",
    "        table_data.append(r)\n",
    "\n",
    "    return table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_all_tables(columns, data):\n",
    "    for k in data.keys():\n",
    "        data[k] = prepare_table_data(columns, data[k])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_all_tables(columns, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2,000 square kilometres'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Australia\"][3][\"Old-growth extent\"].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many of the listed forests are in France?\n",
    "europe = data[\"Europe\"]\n",
    "france = [r for r in europe if \"France\" in r[\"Country\"].text]\n",
    "len(france)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many of the listed forests are in Tasmania?\n",
    "len([r for r in data[\"Australia\"] if \"Tasmania\" in r[\"Area\"].text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total area for Tasmania forests:  200100.0  ha\n"
     ]
    }
   ],
   "source": [
    "# In tasmania, of those that have data, what is the total area of these?\n",
    "australia = data[\"Australia\"]\n",
    "tasmania = [r for r in data[\"Australia\"] if \"Tasmania\" in r[\"Area\"].text]\n",
    "tasmania_area_data = [r for r in tasmania if r[\"Old-growth extent\"] != \"No data\"]\n",
    "\n",
    "total = 0\n",
    "for r in tasmania_area_data:\n",
    "    area = r[\"Old-growth extent\"].text\n",
    "\n",
    "    area = area.replace(\",\", \"\")\n",
    "    val = re.search(\"\\d*\", area).group()\n",
    "    val = float(val)\n",
    "\n",
    "    if \"square kilometres\" in area:\n",
    "        val = val * 100\n",
    "\n",
    "    total += val\n",
    "\n",
    "print(\"Total area for Tasmania forests: \", total, \" ha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From the data of bulgaria's forests, what is the proportion of bulgarias total area that is covered by these?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulgaria_rows = []\n",
    "for row in data[\"Europe\"]:\n",
    "    if row[\"Country\"].text.strip() == \"Bulgaria\":\n",
    "        bulgaria_rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the link of the bulgaria article\n",
    "bulgaria_link = \"https://wikipedia.org\" + bulgaria_rows[0][\"Country\"].a[\"href\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_html(bulgaria_link, path=\"HTML/bulgaria.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"HTML/bulgaria.html\", \"r\", encoding = \"utf-8\") as f:\n",
    "    html_bulgaria = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Bulgaria - Wikipedia</title>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bulgaria_soup = BeautifulSoup(html_bulgaria, \"html.parser\")\n",
    "bulgaria_soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bulgaria_area(tag):\n",
    "    return tag.name == \"td\" and 'km' in tag.text and 'Total' in tag.parent.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_tags = [t.text for t in bulgaria_soup.find_all(get_bulgaria_area)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'110,993.6[3]\\xa0km2 (42,854.9\\xa0sq\\xa0mi) (103rd)'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_tag = km_tags[0]\n",
    "area_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_area = re.search(\"\\d+(?:,\\d{3})*(?:\\.\\d*)?\", area_tag).group()\n",
    "b_area = float(b_area.replace(',', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_area = b_area * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1107122.6"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_total = 0\n",
    "for row in bulgaria_rows:\n",
    "    forest_data = row['Old-growth extent'].text\n",
    "    forest_data = re.search(\"\\d+(?:,\\d{3})*(?:\\.\\d*)?\", forest_data).group()\n",
    "    forest_data = float(forest_data.replace(',', ''))\n",
    "\n",
    "    forest_total += forest_data\n",
    "\n",
    "forest_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of bulgarian land area accounted for old growth: 9.97465%\n"
     ]
    }
   ],
   "source": [
    "print(f'Percentage of bulgarian land area accounted for old growth: {round((forest_total / b_area)*100, 5)}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
